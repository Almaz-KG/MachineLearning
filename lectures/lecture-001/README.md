## Искусственный интеллект и машинное обучение
### Лекция 1. Введение в машинное обучение

`Машинное обучение` — обширный подраздел искусственного интеллекта и математической статистики, изучающий методы построения алгоритмов, способных обучаться на основе эмпирических данных.

Машинное обучение находится на стыке `математической статистики`, `методов оптимизации` и классических математических дисциплин, но имеет также и собственную специфику, связанную с проблемами вычислительной эффективности и переобучения. 

Целью машинного обучения является частичная или полная автоматизация решения сложных профессиональных задач в самых разных областях человеческой деятельности.

##### Основные стандартные типы задач
`Обучение с учителем (supervised learning)` — наиболее распространённый случай. Каждый прецедент представляет собой пару «объект, ответ». Требуется найти зависимость ответов от описаний объектов и построить алгоритм, принимающий на входе описание объекта и выдающий на выходе ответ.
- `Задача классификации (classification)` отличается тем, что множество допустимых ответов конечно. Их называют метками классов (class label).
- `Задача регрессии (regression)` отличается тем, что допустимым ответом является действительное число или числовой вектор.
- `Задача ранжирования (learning to rank)` отличается тем, что ответы надо получить сразу на множестве объектов, после чего отсортировать их по значениям ответов. Может сводиться к задачам классификации или регрессии. Часто применяется в информационном поиске и анализе текстов.
- `Задача прогнозирования (forecasting)` отличается тем, что объектами являются отрезки временных рядов, обрывающиеся в тот момент, когда требуется сделать прогноз на будущее. Для решения задач прогнозирования часто удаётся приспособить методы регрессии или классификации, причём во втором случае речь идёт скорее о задачах принятия решений.

`Обучение без учителя (unsupervised learning)` В этом случае ответы не задаются, и требуется искать зависимости между объектами.
- `Задача кластеризации (clustering)` заключается в том, чтобы сгруппировать объекты в кластеры, используя данные о попарном сходстве объектов. Функционалы качества могут определяться по-разному, например, как отношение средних межкластерных и внутрикластерных расстояний.
- `Задача поиска ассоциативных правил (association rules learning)`. Исходные данные представляются в виде признаковых описаний. Требуется найти такие наборы признаков, и такие значения этих признаков, которые особенно часто (неслучайно часто) встречаются в признаковых описаниях объектов.
- `Задача фильтрации выбросов (outliers detection)` — обнаружение в обучающей выборке небольшого числа нетипичных объектов. В некоторых приложениях их поиск является самоцелью (например, обнаружение мошенничества). В других приложениях эти объекты являются следствием ошибок в данных или неточности модели, то есть шумом, мешающим настраивать модель, и должны быть удалены из выборки
- `Задача построения доверительной области (quantile estimation)` — @TODO Добавить описание
- `Задача сокращения размерности (dimensionality reduction)` заключается в том, чтобы по исходным признакам с помощью некоторых функций преобразования перейти к наименьшему числу новых признаков, не потеряв при этом никакой существенной информации об объектах выборки. В классе линейных преобразований наиболее известным примером является метод главных компонент.
- `Задача заполнения пропущенных значений (missing values)` — замена недостающих значений в матрице объекты–признаки их прогнозными значениями.

`Частичное обучение (semi-supervised learning)` занимает промежуточное положение между обучением с учителем и без учителя. Каждый прецедент представляет собой пару «объект, ответ», но ответы известны только на части прецедентов. Пример прикладной задачи — автоматическая рубрикация большого количества текстов при условии, что некоторые из них уже отнесены к каким-то рубрикам.

`Обучение с подкреплением (reinforcement learning)` - роль объектов играют пары «ситуация, принятое решение», ответами являются значения функционала качества, характеризующего правильность принятых решений (реакцию среды). Как и в задачах прогнозирования, здесь существенную роль играет фактор времени. Примеры прикладных задач: формирование инвестиционных стратегий, автоматическое управление технологическими процессами, самообучение роботов, и т.д.

`Динамическое обучение (online learning)` может быть как обучением с учителем, так и без учителя. Специфика в том, что прецеденты поступают потоком. Требуется немедленно принимать решение по каждому прецеденту и одновременно доучивать модель зависимости с учётом новых прецедентов. Как и в задачах прогнозирования, здесь существенную роль играет фактор времени.

`Активное обучение (active learning)` отличается тем, что обучаемый имеет возможность самостоятельно назначать следующий прецедент, который станет известен.

`Метаобучение (meta-learning или learning-to-learn)` отличается тем, что прецедентами являются ранее решённые задачи обучения. Требуется определить, какие из используемых в них эвристик работают более эффективно. Конечная цель — обеспечить постоянное автоматическое совершенствование алгоритма обучения с течением времени.

##### Специфические прикладные задачи
Некоторые задачи, имеют черты сразу нескольких стандартных типов задач обучения, поэтому их трудно однозначно отнести к какому-то одному типу.
- Формирование инвестиционного портфеля (portfolio selection) — это динамическое обучение с подкреплением, в котором очень важен отбор информативных признаков. Роль признаков играют финансовые инструменты. Состав оптимального набора признаков (портфеля) может изменяться со временем. Признаком качества является долгосрочная прибыль от инвестирования в данную стратегию управления портфелем.
- Коллаборативная фильтрация (collaborative filtering) — это прогнозирование предпочтений пользователей на основе их прежних предпочтений и предпочтений схожих пользователей. Применяются элементы классификации, кластеризации и восполнения пропущенных данных. 

##### Спектр приложений машинного обучения:
   - Приложения в биоинформатике
   - Приложения в медицине
     - Медицинская диагностика
   - Приложения в геологии и геофизике
   - Приложения в социологии
   - Приложения в экономике
     - Кредитный скоринг (credit scoring)
     - Предсказание ухода клиентов (churn prediction)
     - Обнаружение мошенничества (fraud detection)
     - Биржевой технический анализ (technical analysis)
     - Биржевой надзор (market surveillance)
   - Приложения в технике
     - Техническая диагностика
     - Робототехника
     - Компьютерное зрение
     - Распознавание речи
   - Приложения в офисной автоматизации
     - Распознавание текста
     - Обнаружение спама
     - Категоризация документов
     - Распознавание рукописного ввода
  
Сфера применений машинного обучения постоянно расширяется. Повсеместная информатизация приводит к накоплению огромных объёмов данных во всех сферах человеческой жизнедеятельности. На этих данных сегодня становится возможным строить новые алгоритмы для решения насущных потребностей общества 

##### Методы машинного обучения
- Статистическая классификация
- Классификация на основе сходства
- Классификация на основе разделимости
    Большая группа методов классификации основана на явном построении разделяющей поверхности в пространстве объектов. Из них чаще всех применяются `Линейные классификаторы`:
    - однослойный персептрон;
    - логистическая регрессия;
    - машина опорных векторов (Метод опорных векторов, SVM)
- Нейронные сети
    Нейронные сети основаны на принципе коннективизма — в них соединяется большое количество относительно простых элементов, а обучение сводится к построению оптимальной структуры связей и настройке параметров связей.
    - многослойный персептрон;
    - метод стохастического градиента
    - метод обратного распространения ошибки = Backpropagation = Backprop
    - Нейронная сеть Кохонена ;
    - гибридная сеть встречного распространения;
    - сеть радиальных базисных функций;
    - оптимальное усечение сети = Optimal Brain Damage = OBD.
- Индукция правил (поиск закономерностей)
    Логические алгоритмы классификации представляют собой композиции простых, легко интерпретируемых правил.
    - решающее дерево;
    - решающий список;
    - решающий лес;
    - тестовый алгоритм;
    - алгоритм вычисления оценок;
    - дерево регрессии;
    - ассоциативные правила = правила ассоциации.
- Кластеризация
    - графовые алгоритмы кластеризации;
    - cтатистические алгоритмы кластеризации;
    - Алгоритм ФОРЕЛЬ;
    - Быстрый алгоритм нахождения метрических сгущений с использованием матрицы парных расстояний в ранговых шкалах.;
    - Алгоритм k средних = k-means;
    - иерархическая кластеризация;
    - ко-кластеризация;
    - Нейронная сеть Кохонена;
    - Ансамбль кластеризаторов,
- Регрессия
    - линейная регрессия;
    - нелинейная регрессия;
    - векторная регрессия;
    - логистическая регрессия.
- Алгоритмические композиции
    - взвешенное голосование;
    - бустинг;
    - бэггинг;
    - метод случайных подпространств;
    - метод комитетов;
    - смесь экспертов.
- Сокращение размерности
    - селекция признаков = отбор признаков;
    - метод главных компонент;
    - метод независимых компонент;
    - многомерное шкалирование.
- Выбор модели
    - минимизация эмпирического риска;
    - структурная минимизация риска;
    - минимум длины описания;
    - критерий Акаике = AIC;
    - байесовский информационный критерий = BIC;
    - скользящий контроль;
    - извлечение признаков;
    - метод группового учёта аргументов = МГУА = самоорганизация моделей;
    - случайный поиск с адаптацией;
    - генетический алгоритм.
- Байесовский вывод
    - байесовский вывод
    - байесовский информационный критерий = BIC;
    - метод релевантных векторов = RVM
    - байесовская сеть
    
    
### Источники
- [machinelearning.ru](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5)
- [sim0nsays Лекция - 1 Введение](https://www.youtube.com/watch?v=riLQCudri7Q)
- [Блог Open Data Science на Habrahabr](https://habr.com/company/ods/page6/)

### Домашнее задание

- [x] Зарегистрироваться в [Kaggle](https://www.kaggle.com/)
- [ ] Выполнить задачу про Титаник на Kaggle
- [ ] Выполнить задачу про Классификацию Ирисок на Kaggle
- [ ] Выполнить задачу про распознаванию рукописных чисел

