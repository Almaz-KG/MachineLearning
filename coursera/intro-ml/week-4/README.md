#### НЕДЕЛЯ 4 
#### Линейная регрессия

`Регрессия` – это условное математическое ожидание непрерывной зависимой (выходной) переменной при наблюдаемых значениях независимых (входных) переменных. 
`Линейная регрессия (Linear regression)` —  регрессия основаная на гипотезе, что искомая зависимость – линейная. 
Каждая независимая переменная вносит аддитивный вклад в результирующее значение с некоторым весом, называемом коэффициентом регрессии.

Регрессия называется простой, если входная переменная одна. Однако такая модель является слишком грубым приближением действительности, 
и на практике, как правило, интересны зависимости от нескольких переменных (многомерная регрессия).

Модель многомерной линейной регрессии называется так из-за того, что вычисляет прогноз как линейную комбинацию многих признаков. 
В двумерном случае обученная модель представляет собой гиперплоскость

Построение линейной регрессии заключается в расчете её коэффициентов методом наименьших квадратов. 
Регрессия по методу наименьших квадратов (МНК) часто может стать неустойчивой, то есть сильно зависящей от обучающих данных, 
что обычно является проявлением тенденции к переобучению. Избежать такого переобучения помогает регуляризация - общий метод, заключающийся 
в наложении дополнительных ограничений на искомые параметры, которые могут предотвратить излишнюю сложность модели. 
Смысл процедуры заключается в “стягивании” в ходе настройки вектора коэффициентов  β  таким образом, чтобы они в среднем оказались несколько 
меньше по абсолютной величине, чем это было бы при оптимизации по МНК.

Например, если выходная переменная является категориальной или бинарной, приходится использовать различные модификации регрессии.

Несмотря на свою универсальность, линейная регрессионная модель не всегда пригодна для качественного предсказания зависимой переменной.
Задача многомерной линейной регрессии модет быть решена через сингулярное разложение
Мультиколлинеарность приводит к плохой обусловленности, неустойчивости и переобучению
Методы устранения мультиколлинеарности (гребневая регрессия, метод главных компонент) также связаны с сингулярным разложением

##### Гребневая регрессия
Гребневая регрессия (Ridge-regression) – усовершенствование линейной регрессии с повышенной устойчивостью к ошибкам, налагающая 
ограничения на коэффициенты регрессии для получения куда более приближенного к реальности результата. Вдобавок, этот результат 
гораздо проще интерпретировать. Применяется метод для борьбы с переизбыточностью данных, когда независимые переменные коррелируют 
друг с другом (мультиколлинеарность). Это модель многомерной линейной регрессии с L2 регуляризатором. 

##### Метод LASSO
Лассо-регрессия сходна с гребневой, за исключением того, что коэффициенты регрессии могут равняться нулю (часть признаков при этом исключается из модели).

Сравнение 
- Гребневая регрессия  удобно вводится и интерпретируется через сингулярное разложение
- Гребневая регрессия сокращает веса признаков
- Lasso обнуляет веса признаков
- Оба метода имеют параметр регуляризации (селективности), позволяющий определять число признаков (сложность модели) по внешним критериям (по кросс-валидации)


